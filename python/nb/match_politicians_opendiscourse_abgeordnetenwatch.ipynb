{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import open_discourse.definitions.path_definitions as path_definitions\n",
    "\n",
    "engine = create_engine(\"postgresql://postgres:postgres@localhost:5432/next\")\n",
    "\n",
    "## Load Data\n",
    "# Load Abgeordnetenwatch Data from API\n",
    "all_data = []\n",
    "page = 1\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    if page % 10 == 0:\n",
    "        print(f\"Page {page}\")\n",
    "    example = f\"https://www.abgeordnetenwatch.de/api/v2/politicians?page={str(page)}\"\n",
    "    response = requests.get(example)\n",
    "    r = response.json()\n",
    "    last_count = int(r[\"meta\"][\"result\"][\"count\"])\n",
    "    all_data.extend(r[\"data\"])\n",
    "    if last_count == 0:\n",
    "        break\n",
    "    page += 1\n",
    "\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df.shape\n",
    "\n",
    "# filter for members of Bundestag\n",
    "df_mbd = df.loc[df.ext_id_bundestagsverwaltung.notnull()]\n",
    "\n",
    "# Load Open Discourse Data\n",
    "PEOPLE = path_definitions.DATA_FINAL / \"politicians.csv\"\n",
    "politicians = pd.read_csv(PEOPLE)\n",
    "# remove duplicates by keeping first\n",
    "politicians = politicians.drop_duplicates(\n",
    "    subset=[\"ui\", \"first_name\", \"last_name\"], keep=\"first\"\n",
    ")\n",
    "politicians = politicians.drop_duplicates(subset=[\"ui\"], keep=\"first\")\n",
    "politicians = politicians.drop(\n",
    "    [\n",
    "        \"electoral_term\",\n",
    "        \"faction_id\",\n",
    "        \"institution_type\",\n",
    "        \"institution_name\",\n",
    "        \"constituency\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "politicians.columns = [\n",
    "    \"id\",\n",
    "    \"first_name\",\n",
    "    \"last_name\",\n",
    "    \"birth_place\",\n",
    "    \"birth_country\",\n",
    "    \"birth_date\",\n",
    "    \"death_date\",\n",
    "    \"gender\",\n",
    "    \"profession\",\n",
    "    \"aristocracy\",\n",
    "    \"academic_title\",\n",
    "]\n",
    "print(\n",
    "    f\"We have {df_mbd.shape[0]} members of Bundestag in the Abgeordnetenwatch API and {politicians.shape[0]} MdB in the Open Discourse data.\"\n",
    ")\n",
    "print(\n",
    "    f\"The discrepancy is due to the fact that Abgeordnetenwatch started collecting data in the 2000s, while Open Discourse has a complete dataset from Bundestagsverwaltung.\"\n",
    ")\n",
    "\n",
    "## Prep data\n",
    "df_mbd[\"year_of_birth\"] = df_mbd[\"year_of_birth\"].fillna(\"-1\")\n",
    "df_mbd[\"year_of_birth\"] = df_mbd[\"year_of_birth\"].apply(\n",
    "    lambda x: str(int(x)) if x != \"-1\" else x\n",
    ")\n",
    "politicians[\"year_of_birth\"] = politicians[\"birth_date\"].apply(\n",
    "    lambda x: str(pd.to_datetime(x, format=\"mixed\").year) if x != \"-1\" else x\n",
    ")\n",
    "# remove capitalization and replace - with space for first and last names in both datasets\n",
    "for col in [\"first_name\", \"last_name\"]:\n",
    "    df_mbd[col] = df_mbd[col].str.strip().str.lower().str.replace(\"-\", \" \")\n",
    "    politicians[col] = politicians[col].str.strip().str.lower().str.replace(\"-\", \" \")\n",
    "\n",
    "\n",
    "# since df_mbd is the smalller dataset, we match onto this one\n",
    "# start with exact match via left join on first name, last name and birth year\n",
    "merge_cols = [\"first_name\", \"last_name\", \"year_of_birth\"]\n",
    "exact_matches_unique = (\n",
    "    df_mbd.merge(\n",
    "        politicians,\n",
    "        how=\"left\",\n",
    "        left_on=merge_cols,\n",
    "        right_on=[\"first_name\", \"last_name\", \"year_of_birth\"],\n",
    "        suffixes=(\"_aw\", \"_od\"),\n",
    "    )\n",
    "    .drop_duplicates(\"id_aw\", keep=False)\n",
    "    .dropna(subset=[\"id_od\"])\n",
    ")\n",
    "df_mdb_left = df_mbd.loc[~df_mbd.id.isin(exact_matches_unique.id_aw)]\n",
    "politicians_left = politicians.loc[~politicians.id.isin(exact_matches_unique.id_od)]\n",
    "print(\n",
    "    f\"Of {df_mbd.shape[0]} politicians in the Abgeordnetenwatch API, {exact_matches_unique.shape[0]} could be matched exactly on {str(merge_cols)}, and {df_mdb_left.shape[0]} are left to be matched.\"\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def fuzzy_match_cols(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    id_cols: List[str],\n",
    "    match_cols: List[str],\n",
    "    weights=None,\n",
    "    threshold=80,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Match names between two dataframes using fuzzy string matching.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df1, df2 : pandas.DataFrame\n",
    "        DataFrames containing the names to match\n",
    "    fname_col1, fname_col2 : str\n",
    "        Column names for first names in df1 and df2\n",
    "    lname_col1, lname_col2 : str\n",
    "        Column names for last names in df1 and df2\n",
    "    threshold : int\n",
    "        Minimum match score (0-100) to consider a match\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with matched names and their scores\n",
    "    \"\"\"\n",
    "    weights = len(match_cols) * [1] if weights is None else weights\n",
    "    # Clean names: lowercase and strip whitespace\n",
    "    for df in [df1, df2]:\n",
    "        for col in match_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].str.strip()\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Create all possible pairs of names\n",
    "    for _, row1 in df1.iterrows():\n",
    "        for _, row2 in df2.iterrows():\n",
    "            match_scores = []\n",
    "            for col, weight in zip(match_cols, weights):\n",
    "                match_scores.append(fuzz.ratio(str(row1[col]), str(row2[col])) * weight)\n",
    "\n",
    "            # Calculate overall match score\n",
    "            match_score = sum(match_scores) / sum(weights)\n",
    "\n",
    "            # If score exceeds threshold, add to matches\n",
    "            if match_score >= threshold:\n",
    "                data = {\n",
    "                    \"df1_index\": row1[id_cols[0]],\n",
    "                    \"df2_index\": row2[id_cols[1]],\n",
    "                    \"overall_score\": match_score,\n",
    "                }\n",
    "                for col in match_cols:\n",
    "                    data[f\"df1_{col}\"] = row1[col]\n",
    "                    data[f\"df2_{col}\"] = row2[col]\n",
    "                matches.append(data)\n",
    "\n",
    "    # Convert matches to DataFrame and sort by score\n",
    "    matches_df = pd.DataFrame(matches).sort_values(\"overall_score\", ascending=False)\n",
    "\n",
    "    return matches_df\n",
    "\n",
    "\n",
    "# Find matches\n",
    "matches = fuzzy_match_cols(\n",
    "    df_mdb_left,\n",
    "    politicians_left,\n",
    "    id_cols=[\"id\", \"id\"],\n",
    "    match_cols=[\"first_name\", \"last_name\"],\n",
    "    threshold=50,\n",
    ")\n",
    "matches[\"df1_year_of_birth\"] = matches[\"df1_index\"].map(\n",
    "    df_mdb_left.set_index(\"id\")[\"year_of_birth\"]\n",
    ")\n",
    "matches[\"df2_year_of_birth\"] = matches[\"df2_index\"].map(\n",
    "    politicians_left.set_index(\"id\")[\"year_of_birth\"]\n",
    ")\n",
    "# highest_matches = matches.drop_duplicates(subset=[\"df1_index\"], keep=\"first\")\n",
    "highest_matches_w_matching_birthyear_over_70 = matches.loc[\n",
    "    (matches.df1_year_of_birth == matches.df2_year_of_birth)\n",
    "    & (matches.df1_year_of_birth != \"-1\")\n",
    "    & (matches.overall_score > 70)\n",
    "].drop_duplicates(subset=[\"df1_index\"], keep=\"first\")\n",
    "rest = matches.loc[\n",
    "    ~matches.df1_index.isin(highest_matches_w_matching_birthyear_over_70.df1_index)\n",
    "]\n",
    "# remove non-matching birth years except where birth year is -1\n",
    "# these need to be matched manually\n",
    "rest = rest.loc[\n",
    "    (rest.df1_year_of_birth == rest.df2_year_of_birth)\n",
    "    | (rest.df1_year_of_birth == \"-1\")\n",
    "].drop_duplicates(subset=[\"df1_index\"], keep=\"first\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
